{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGkQa76Fucq2",
        "outputId": "234ef968-2e26-43b5-d46f-bb6462e7ee86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# to be completed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/'My Drive'/'IEMOCAP_full_release_withoutVideos_sentenceOnly'/'IEMOCAP_full_release'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CO-QBg7GiYg",
        "outputId": "739ee7fe-8d57-49e7-b31c-7499d2a2e289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/IEMOCAP_full_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLtHzeJd4JrN",
        "outputId": "b6c012db-e737-4719-9bee-1ef1a58998ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/IEMOCAP_full_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S1PhQVziOtB"
      },
      "source": [
        "***UNZIP THE IMOCAP DATASETS***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojofRy8zS0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965b3f5b-a727-49f1-e99c-d79bf805727c"
      },
      "source": [
        "#!pip install transformers\n",
        "#!pip install tensorboardx\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5rruwKFiX0x"
      },
      "source": [
        "*PREPROCESIING THE IMPCAP AUDIO FILES* : THANKS TO ***https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb  and https://github.com/david-yoon/multimodal-speech-emotion/blob/master/preprocessing/IEMOCAP_01_wav_to_feature.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmyifjHXii-K"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.backend_bases import RendererBase\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from scipy.fftpack import fft\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wan_pCAlZj7"
      },
      "source": [
        "**read the all the files in a list at sentence level**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkcz86elmCv6"
      },
      "source": [
        "import os\n",
        "import chardet\n",
        "\n",
        "def file_search(dirname, ret, list_avoid_dir=[]):\n",
        "    filenames = os.listdir(dirname)\n",
        "\n",
        "    for filename in filenames:\n",
        "        full_filename = os.path.join(dirname, filename)\n",
        "\n",
        "        if os.path.isdir(full_filename) :\n",
        "            if full_filename.split('/')[-1] in list_avoid_dir:\n",
        "                continue\n",
        "            else:\n",
        "                file_search(full_filename, ret, list_avoid_dir)\n",
        "\n",
        "        else:\n",
        "            ret.append( full_filename )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKP6PwqvILJT"
      },
      "source": [
        "***below code is:***\n",
        "https://github.com/Escanor1996/Speech-Emotion-Recognition-SER-/blob/master/SER.ipynb\n",
        "\n",
        "***Paper:*** Attention Based Fully Convolutional Network for Speech Emotion Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788jVVFCH7vb"
      },
      "source": [
        "def audio2spectrogram(filepath):\n",
        "    #fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    #print('samplerate',samplerate)\n",
        "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
        "    #print(spectrogram.shape)\n",
        "    #print(type(spectrogram))\n",
        "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
        "    return spectrogram\n",
        "\n",
        "def audio2wave(filepath):\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    plt.plot(test_sound)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkiYHO6MH3Kr"
      },
      "source": [
        "def log_specgram(audio, sample_rate, window_size=40,\n",
        "                 step_size=20, eps=1e-10):\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "    #print('noverlap',noverlap)\n",
        "    #print('nperseg',nperseg)\n",
        "    freqs, _, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv66rHV3pLkE"
      },
      "source": [
        "N_CHANNELS = 3\n",
        "def get_3d_spec(Sxx_in, moments=None):\n",
        "    if moments is not None:\n",
        "        (base_mean, base_std, delta_mean, delta_std,\n",
        "             delta2_mean, delta2_std) = moments\n",
        "    else:\n",
        "        base_mean, delta_mean, delta2_mean = (0, 0, 0)\n",
        "        base_std, delta_std, delta2_std = (1, 1, 1)\n",
        "    h, w = Sxx_in.shape\n",
        "    right1 = np.concatenate([Sxx_in[:, 0].reshape((h, -1)), Sxx_in], axis=1)[:, :-1]\n",
        "    delta = (Sxx_in - right1)[:, 1:]\n",
        "    delta_pad = delta[:, 0].reshape((h, -1))\n",
        "    delta = np.concatenate([delta_pad, delta], axis=1)\n",
        "    right2 = np.concatenate([delta[:, 0].reshape((h, -1)), delta], axis=1)[:, :-1]\n",
        "    delta2 = (delta - right2)[:, 1:]\n",
        "    delta2_pad = delta2[:, 0].reshape((h, -1))\n",
        "    delta2 = np.concatenate([delta2_pad, delta2], axis=1)\n",
        "    base = (Sxx_in - base_mean) / base_std\n",
        "    delta = (delta - delta_mean) / delta_std\n",
        "    delta2 = (delta2 - delta2_mean) / delta2_std\n",
        "    stacked = [arr.reshape((h, w, 1)) for arr in (base, delta, delta2)]\n",
        "    return np.concatenate(stacked, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMNBRvIxRfUc"
      },
      "source": [
        "Spectrogram: one axis represents the time(X-axis), the second axis represents frequencies(Y-axis) and the colors represent magnitude (amplitude) of the observed frequency at a particular time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCQegmJSYX-T"
      },
      "source": [
        "***read the processed transcription file to collect the labels***"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PAPcc4xjyHLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk1hbZ6Jh6_q"
      },
      "outputs": [],
      "source": [
        "def get_labels(annot_file, file_name):\n",
        "\n",
        "    f = open(annot_file, 'r').read()\n",
        "    f = f.split('\\n')\n",
        "    f = f[2:]\n",
        "\n",
        "    for data in f:\n",
        "\n",
        "        if len(data) > 0:\n",
        "            if data[0] == '[':\n",
        "                data2 = data.split('\\t')\n",
        "\n",
        "                if data2[1] == file_name:\n",
        "                    emo = data2[2]\n",
        "                    vad = data2[3][1:-1].split(', ')\n",
        "                    return emo, [float(x) for x in vad]\n",
        "\n",
        "    raise ValueError('Label not found')\n",
        "\n",
        "def get_mocap_rot(path):\n",
        "\n",
        "    f = open(path, 'r').read()\n",
        "    f = np.array(f.split('\\n'))\n",
        "    header = f[0].split(' ')\n",
        "    xyz = f[1].split(' ')\n",
        "    f = f[2:]\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "    for data in f:\n",
        "        data2 = data.split(' ')\n",
        "        if(len(data2)<2):\n",
        "            continue\n",
        "        dic = {'frame': data2[0], 'time': data2[1],\n",
        "               'markers': np.array(data2[2:]).astype(float)}\n",
        "        data_list.append(dic)\n",
        "\n",
        "    return header, xyz, data_list\n",
        "\n",
        "def get_wav(path):\n",
        "    x, sr = librosa.load(path, sr=16000)\n",
        "    return x, sr\n",
        "\n",
        "def get_ph_fa(path):\n",
        "    f = open(path, 'r').read()\n",
        "    f = np.array(f.split('\\n'))\n",
        "    header = f[0].split()\n",
        "    f = f[1:-2]\n",
        "    data_list = []\n",
        "\n",
        "    for data in f:\n",
        "        data2 = data.split()\n",
        "        dic = {'SFrm':np.array(data2[0]).astype(int),\n",
        "               'EFrm':np.array(data2[1]).astype(int),\n",
        "               'SegAScr':np.array(data2[2]).astype(int),\n",
        "               'Phone':data2[3]}\n",
        "        data_list.append(dic)\n",
        "\n",
        "    return header, data_list\n",
        "\n",
        "def frame_to_s(fr):\n",
        "    return (fr+2)*10/1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmXOncwLSThg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "98418730-ec5a-4fb9-83b1-4a9a03df404b"
      },
      "source": [
        "import pandas as pd\n",
        "#'/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/IEMOCAP_full_release/'\n",
        "#df=pd.read_excel('/content/drive/My Drive/Imocap_text/processed_tran.xlsx')\n",
        "\n",
        "root_path = '/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly'\n",
        "\n",
        "df = pd.read_csv(os.path.join(root_path, 'iemocap.csv'))\n",
        "sessions = [1, 2, 3, 4, 5]\n",
        "df = df[df['session'].isin(sessions)]\n",
        "\n",
        "# Remove unwanted emotions and empty values\n",
        "unwanted_emotions = ['xxx', '', 'oth', 'dis', 'sur', 'fea']\n",
        "df = df[~df['emotion'].isin(unwanted_emotions)]\n",
        "\n",
        "# Calculate annotator difference\n",
        "df['annotator_difference'] = df['n_annotators'] - df['agreement']\n",
        "\n",
        "# Filter by annotator difference\n",
        "df = df[df['annotator_difference'] <= 1]\n",
        "\n",
        "# Replace 'exc' emotion with 'hap'\n",
        "df.loc[df['emotion'] == 'exc', 'emotion'] = 'hap'\n",
        "\n",
        "\n",
        "emotions_count_before = df['emotion'].value_counts()\n",
        "print(\"Emotions count before filtering:\")\n",
        "print(emotions_count_before)\n",
        "\n",
        "# Group by emotion and select first 550 rows of each group\n",
        "df = df.groupby('emotion').head(550)\n",
        "\n",
        "# Count the occurrences of each emotion after filtering\n",
        "emotions_count_after = df['emotion'].value_counts()\n",
        "print(\"\\nEmotions count after filtering:\")\n",
        "print(emotions_count_after)\n",
        "\n",
        "# Display the first 5 rows\n",
        "display(df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotions count before filtering:\n",
            "fru    1692\n",
            "neu    1551\n",
            "hap    1471\n",
            "ang    1077\n",
            "sad    1000\n",
            "Name: emotion, dtype: int64\n",
            "\n",
            "Emotions count after filtering:\n",
            "neu    550\n",
            "fru    550\n",
            "ang    550\n",
            "hap    550\n",
            "sad    550\n",
            "Name: emotion, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Unnamed: 0  session  method gender  n_annotators  agreement emotion  \\\n",
              "0              0        1  script      F             3          3     neu   \n",
              "1              1        1  script      F             3          2     fru   \n",
              "4              4        1  script      F             3          2     neu   \n",
              "6              6        1  script      F             3          2     ang   \n",
              "7              7        1  script      F             3          2     ang   \n",
              "...          ...      ...     ...    ...           ...        ...     ...   \n",
              "5350        5350        3   impro      M             4          3     ang   \n",
              "5493        5493        3  script      M             3          3     ang   \n",
              "5494        5494        3  script      M             3          2     ang   \n",
              "5497        5497        3  script      M             3          2     ang   \n",
              "5515        5515        3  script      M             3          2     ang   \n",
              "\n",
              "      valence  activation  dominance  \\\n",
              "0         2.5         2.0        2.0   \n",
              "1         2.5         2.0        2.5   \n",
              "4         2.0         3.0        3.0   \n",
              "6         2.0         3.5        3.0   \n",
              "7         2.0         3.5        2.5   \n",
              "...       ...         ...        ...   \n",
              "5350      2.0         3.0        4.0   \n",
              "5493      2.0         4.0        4.0   \n",
              "5494      3.0         2.5        3.0   \n",
              "5497      2.0         4.0        3.5   \n",
              "5515      1.5         4.5        4.0   \n",
              "\n",
              "                                               wav_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/wav/Se...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/wav/Se...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/wav/Se...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/wav/Se...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/wav/Se...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/wav/Se...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/wav/Se...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/wav/Se...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/wav/Se...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/wav/Se...   \n",
              "\n",
              "                                     MOCAP_rotated_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "\n",
              "                                        MOCAP_head_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "\n",
              "                                        MOCAP_hand_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/MOCAP_...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/MOCAP_...   \n",
              "\n",
              "                                             FA_ph_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "\n",
              "                                             FA_st_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "\n",
              "                                             FA_sy_path  \\\n",
              "0     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "1     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "4     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "6     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "7     IEMOCAP_full_release/Session1/sentences/Forced...   \n",
              "...                                                 ...   \n",
              "5350  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5493  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5494  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5497  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "5515  IEMOCAP_full_release/Session3/sentences/Forced...   \n",
              "\n",
              "                                             FA_wd_path  annotator_difference  \n",
              "0     IEMOCAP_full_release/Session1/sentences/Forced...                     0  \n",
              "1     IEMOCAP_full_release/Session1/sentences/Forced...                     1  \n",
              "4     IEMOCAP_full_release/Session1/sentences/Forced...                     1  \n",
              "6     IEMOCAP_full_release/Session1/sentences/Forced...                     1  \n",
              "7     IEMOCAP_full_release/Session1/sentences/Forced...                     1  \n",
              "...                                                 ...                   ...  \n",
              "5350  IEMOCAP_full_release/Session3/sentences/Forced...                     1  \n",
              "5493  IEMOCAP_full_release/Session3/sentences/Forced...                     0  \n",
              "5494  IEMOCAP_full_release/Session3/sentences/Forced...                     1  \n",
              "5497  IEMOCAP_full_release/Session3/sentences/Forced...                     1  \n",
              "5515  IEMOCAP_full_release/Session3/sentences/Forced...                     1  \n",
              "\n",
              "[2750 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c216e2e-eceb-40cd-9780-c843d32a2afa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>session</th>\n",
              "      <th>method</th>\n",
              "      <th>gender</th>\n",
              "      <th>n_annotators</th>\n",
              "      <th>agreement</th>\n",
              "      <th>emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>activation</th>\n",
              "      <th>dominance</th>\n",
              "      <th>wav_path</th>\n",
              "      <th>MOCAP_rotated_path</th>\n",
              "      <th>MOCAP_head_path</th>\n",
              "      <th>MOCAP_hand_path</th>\n",
              "      <th>FA_ph_path</th>\n",
              "      <th>FA_st_path</th>\n",
              "      <th>FA_sy_path</th>\n",
              "      <th>FA_wd_path</th>\n",
              "      <th>annotator_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>script</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>neu</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>script</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>fru</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>script</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>neu</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>script</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ang</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>script</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ang</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session1/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5350</th>\n",
              "      <td>5350</td>\n",
              "      <td>3</td>\n",
              "      <td>impro</td>\n",
              "      <td>M</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>ang</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5493</th>\n",
              "      <td>5493</td>\n",
              "      <td>3</td>\n",
              "      <td>script</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>ang</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5494</th>\n",
              "      <td>5494</td>\n",
              "      <td>3</td>\n",
              "      <td>script</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ang</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5497</th>\n",
              "      <td>5497</td>\n",
              "      <td>3</td>\n",
              "      <td>script</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ang</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5515</th>\n",
              "      <td>5515</td>\n",
              "      <td>3</td>\n",
              "      <td>script</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>ang</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/wav/Se...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/MOCAP_...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>IEMOCAP_full_release/Session3/sentences/Forced...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2750 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c216e2e-eceb-40cd-9780-c843d32a2afa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c216e2e-eceb-40cd-9780-c843d32a2afa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c216e2e-eceb-40cd-9780-c843d32a2afa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da08d648-c234-4116-92c4-8f3e38fcfb40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da08d648-c234-4116-92c4-8f3e38fcfb40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da08d648-c234-4116-92c4-8f3e38fcfb40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2750,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1302,\n        \"min\": 0,\n        \"max\": 5515,\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          2036,\n          1433,\n          3213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"impro\",\n          \"script\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_annotators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"fru\",\n          \"sad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9280573174299208,\n        \"min\": 1.0,\n        \"max\": 5.5,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2.5,\n          4.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"activation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7767859938390874,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          2.0,\n          4.6667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dominance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.83413015455617,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.0,\n          3.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wav_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/wav/Ses02M_script01_2/Ses02M_script01_2_F008.wav\",\n          \"IEMOCAP_full_release/Session1/sentences/wav/Ses01F_impro05/Ses01F_impro05_F012.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MOCAP_rotated_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/MOCAP_rotated/Ses02M_script01_2/Ses02M_script01_2_F008.txt\",\n          \"IEMOCAP_full_release/Session1/sentences/MOCAP_rotated/Ses01F_impro05/Ses01F_impro05_F012.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MOCAP_head_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/MOCAP_head/Ses02M_script01_2/Ses02M_script01_2_F008.txt\",\n          \"IEMOCAP_full_release/Session1/sentences/MOCAP_head/Ses01F_impro05/Ses01F_impro05_F012.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MOCAP_hand_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/MOCAP_hand/Ses02M_script01_2/Ses02M_script01_2_F008.txt\",\n          \"IEMOCAP_full_release/Session1/sentences/MOCAP_hand/Ses01F_impro05/Ses01F_impro05_F012.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FA_ph_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/ForcedAlignment/Ses02M_script01_2/Ses02M_script01_2_F008.phseg\",\n          \"IEMOCAP_full_release/Session1/sentences/ForcedAlignment/Ses01F_impro05/Ses01F_impro05_F012.phseg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FA_st_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/ForcedAlignment/Ses02M_script01_2/Ses02M_script01_2_F008.stseg\",\n          \"IEMOCAP_full_release/Session1/sentences/ForcedAlignment/Ses01F_impro05/Ses01F_impro05_F012.stseg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FA_sy_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/ForcedAlignment/Ses02M_script01_2/Ses02M_script01_2_F008.syseg\",\n          \"IEMOCAP_full_release/Session1/sentences/ForcedAlignment/Ses01F_impro05/Ses01F_impro05_F012.syseg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FA_wd_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2750,\n        \"samples\": [\n          \"IEMOCAP_full_release/Session2/sentences/ForcedAlignment/Ses02M_script01_2/Ses02M_script01_2_F008.wdseg\",\n          \"IEMOCAP_full_release/Session1/sentences/ForcedAlignment/Ses01F_impro05/Ses01F_impro05_F012.wdseg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotator_difference\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RToQ2If_lIbO",
        "outputId": "b30ecadb-10bb-499a-d119-cef1badd17b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list_files = df['wav_path'].tolist()\n",
        "labels = df['emotion'].tolist()\n",
        "#root_path = '/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/IEMOCAP_full_release/'\n",
        "#for x in range(5):\n",
        " #   sess_name = 'Session' + str(x+1)\n",
        "  #  path = root_path + sess_name + '/sentences/wav'\n",
        "   # file_search(path, list_files)\n",
        "   # list_files = sorted(list_files)\n",
        "   # print (sess_name + \", #sum files: \" + str(len(list_files)))\n",
        "#extract_feature( list_files, out_file )\n",
        "#print(list_files[-1])\n",
        "print(len(list_files))\n",
        "print(list_files[0])\n",
        "print(len(labels))\n",
        "print(labels[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2750\n",
            "IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_1/Ses01F_script02_1_F000.wav\n",
            "2750\n",
            "neu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atR-YPWjneVs"
      },
      "source": [
        "***Gettint the labels***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(annot_file, file_name):\n",
        "\n",
        "    f = open(annot_file, 'r').read()\n",
        "    f = f.split('\\n')\n",
        "    f = f[2:]\n",
        "\n",
        "    for data in f:\n",
        "\n",
        "        if len(data) > 0:\n",
        "            if data[0] == '[':\n",
        "                data2 = data.split('\\t')\n",
        "\n",
        "                if data2[1] == file_name:\n",
        "                    emo = data2[2]\n",
        "                    vad = data2[3][1:-1].split(', ')\n",
        "                    return emo, [float(x) for x in vad]\n",
        "\n",
        "    raise ValueError('Label not found')"
      ],
      "metadata": {
        "id": "rkzgE1QbWyJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsY4d9gPm3lC"
      },
      "source": [
        "no_rows=len(list_files)\n",
        "index=0\n",
        "sprectrogram_shape=[]\n",
        "docs = []\n",
        "bookmark=0\n",
        "extraLabel=0\n",
        "for everyFile in list_files:\n",
        "  if(everyFile.split('/')[-1].endswith('.wav')):\n",
        "    #filename=everyFile.split('/')[-1].strip('.wav')\n",
        "    i = list_files.index(everyFile)\n",
        "    lable = labels[i]\n",
        "    #print('label',lable)\n",
        "    #if(lable!=-1):\n",
        "      #sprectrogram_shape.append(audio2spectrogram(everyFile))\n",
        "    root_path = '/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/'\n",
        "    everyFile = root_path + everyFile\n",
        "    spector=audio2spectrogram(everyFile)\n",
        "    spector=get_3d_spec(spector)\n",
        "    npimg = np.transpose(spector,(2,0,1))\n",
        "    input_tensor=torch.tensor(npimg)\n",
        "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "      #X, sample_rate = librosa.load(everyFile, res_type='kaiser_fast',sr=22050*2)\n",
        "      #sample_rate = np.array(sample_rate)\n",
        "      #mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=13),axis=0)\n",
        "      #feature = mfccs\n",
        "    docs.append({\n",
        "      'fileName':everyFile.split('/')[-1].strip('.wav'),\n",
        "         #'feature_mfcc':feature,\n",
        "      'sprectrome':input_batch,\n",
        "       'label':lable\n",
        "              })\n",
        "    index+=1\n",
        "    print('index',index)\n",
        "  else:\n",
        "    extraLabel=extraLabel+1\n",
        "    #print('extraLabel',extraLabel)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPnKlxI1PSmO"
      },
      "source": [
        "***TestAlexNet input***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij-TYGuMPcjZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#from .utils import load_state_dict_from_url\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((12, 12))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        print('features',x.shape)\n",
        "\n",
        "        #x = self.avgpool(x)\n",
        "        #print('avgpool',x.shape)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        #print('flatten',x.shape)\n",
        "        #x = self.classifier(x)\n",
        "        return x\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qClksYw-dtb"
      },
      "source": [
        "***MOdified AlexNet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zQEjewO-hLS"
      },
      "source": [
        "class ModifiedAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ModifiedAlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #print('features',x.shape)\n",
        "        x=torch.flatten(x, start_dim=2)#a1,a2,a3......al{a of dim c}\n",
        "        x=torch.sum(x, dim=2)#a1*alpha1+a2*alpha2+.......+al*alphal\n",
        "        #print(x.shape)\n",
        "        x=self.classifier(x)\n",
        "        #print('classifier',x)\n",
        "        #x=self.softmax(x)\n",
        "        #print('softmax',x)\n",
        "        #x = self.avgpool(x)\n",
        "        #print('avgpool',x.shape)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        #print('flatten',x.shape)\n",
        "        #x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def modifiedAlexNet(pretrained=False, progress=True, **kwargs):\n",
        "    model_modified = ModifiedAlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model_modified.load_state_dict(state_dict)\n",
        "    return model_modified"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBABecl_Gl9N"
      },
      "source": [
        "***create the Modified model instance and initiliaze with the pretraine d model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsIPd9oBGvag"
      },
      "source": [
        "original_model=alexnet(pretrained=True)\n",
        "original_dict = original_model.state_dict()\n",
        "modifiedAlexNet=modifiedAlexNet(pretrained=False)\n",
        "modified_model_dict = modifiedAlexNet.state_dict()\n",
        "pretrained_modified_model_dict = {k: v for k, v in original_dict.items() if k in modified_model_dict}\n",
        "modifiedAlexNet.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ObB4bOBPmA2"
      },
      "source": [
        "***Input code to AlexNet with Audio Files***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(list_files)):\n",
        "  root_path = '/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/'\n",
        "  list_files[i] = root_path + list_files[i]\n",
        "\n",
        "print(list_files[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRCTOnNujPh3",
        "outputId": "783c0cf8-61ff-4fef-a971-3a654ca89424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1H_wIpsIF42ILnS8ZNz7BovI5ga272ikl/IEMOCAP_full_release_withoutVideos_sentenceOnly/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_1/Ses01F_script02_1_F000.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQxmqNSyTWnr",
        "outputId": "83ef84c9-a118-44f8-b907-94a30287be4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x=audio2spectrogram(list_files[40])\n",
        "x=get_3d_spec(x)\n",
        "npimg = np.transpose(x,(2,0,1))\n",
        "input_tensor=torch.tensor(npimg)\n",
        "\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    modifiedAlexNet.to('cuda')\n",
        "with torch.no_grad():\n",
        "    output = modifiedAlexNet(input_batch)\n",
        "    #output.squeeze().shape\n",
        "    #output=torch.flatten(output, start_dim=2)\n",
        "    #print(output.shape)\n",
        "    #output=torch.sum(output, dim=2)\n",
        "    print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-9.3002, -3.8607, -0.9837,  2.5476, 12.3553]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfT1DDnLQg1b"
      },
      "source": [
        "***Inputdata schuffling and deviding the data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7JZNzX9QvM3",
        "outputId": "7f3fdc58-e3a4-4923-d1fd-8b043f2d4113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "random.shuffle(docs)\n",
        "random.shuffle(docs)\n",
        "random.shuffle(docs)\n",
        "total_length=len(docs)\n",
        "train_length=int(.9*total_length)\n",
        "train_list=docs[0:train_length]\n",
        "test_list=docs[train_length:]\n",
        "print('no of items for train ',len(train_list))\n",
        "print('no of items for test ',len(test_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of items for train  2475\n",
            "no of items for test  275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k1pQ5INTvrm"
      },
      "source": [
        "***Plot Training loss and Accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1mv-uS-T2Mo"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwgNOF5oK-JV"
      },
      "source": [
        "***Model Parameter***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzWnvXf5LCIU",
        "outputId": "16f61cc2-9538-46a3-e356-0f6ce1848aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in modifiedAlexNet.named_parameters():\n",
        "      if(param.requires_grad):\n",
        "        print(name)\n",
        "      else:\n",
        "        print('no grad',name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight\n",
            "features.0.bias\n",
            "features.3.weight\n",
            "features.3.bias\n",
            "features.6.weight\n",
            "features.6.bias\n",
            "features.8.weight\n",
            "features.8.bias\n",
            "features.10.weight\n",
            "features.10.bias\n",
            "classifier.1.weight\n",
            "classifier.1.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoSuRA4cKeSy"
      },
      "source": [
        "***optimizer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_BAUU5kKhAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0f41f9-359c-4bf9-83c4-8c877cc3ef9c"
      },
      "source": [
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(modifiedAlexNet.parameters(),\n",
        "                  lr =  2e-4,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "NUM_EPOCHS=16\n",
        "\n",
        "writer = SummaryWriter(log_dir='/content/')\n",
        "total_steps = len(train_list) * NUM_EPOCHS\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYFow8ZlQB67"
      },
      "source": [
        "***Training Loop***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwVwrysXknMr",
        "outputId": "74450d22-b26f-4f3c-9abb-5b7234b9a592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hj8xc3LQFDi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2e9fbb08-10af-4f8e-f331-c7a1b5c67b98"
      },
      "source": [
        "total_steps = 1\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  modifiedAlexNet.train()\n",
        "  for every_trainlist in train_list:\n",
        "    label1=every_trainlist['label']\n",
        "    label1=torch.tensor([label1])\n",
        "    sprectrome=every_trainlist['sprectrome']\n",
        "    if(sprectrome.shape[2]>65):\n",
        "      optimizer.zero_grad()\n",
        "      sprectrome = sprectrome.to('cuda')\n",
        "      label1=label1.to('cuda')\n",
        "      modifiedAlexNet.zero_grad()\n",
        "      output = modifiedAlexNet(sprectrome)\n",
        "      #print('softmax output ',output)\n",
        "      loss = criterion(output, label1)\n",
        "      #print('label1',label1)\n",
        "      #print('loss',loss.item())\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(modifiedAlexNet.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      _, preds = torch.max(output, 1)\n",
        "      accuracy = torch.sum(preds == label1)\n",
        "      #print('accuracy.item()',accuracy.item())\n",
        "      #print('preds',preds)\n",
        "      if total_steps % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "          _, preds = torch.max(output, 1)\n",
        "          accuracy = torch.sum(preds == label1)\n",
        "          #print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'.format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n",
        "          tbwriter.add_scalar('loss', loss.item(), total_steps)\n",
        "          tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n",
        "      total_steps+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e050876ff97c>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mevery_trainlist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlabel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevery_trainlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlabel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0msprectrome\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevery_trainlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sprectrome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msprectrome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytSK9YJdzDh2"
      },
      "source": [
        "***save and load the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyEVoGs-zHZm"
      },
      "source": [
        "torch.save(modifiedAlexNet, '/content/drive/My Drive/savedModel/model_audio_new_opt.pt')\n",
        "model=torch.load('/content/drive/My Drive/savedModel/model_audio_new_opt.pt')\n",
        "model.eval()\n",
        "model.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfuJ5F0cysjU"
      },
      "source": [
        "***testing lopp***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYbcOfizywFG"
      },
      "source": [
        "y_actu=[]\n",
        "y_pred=[]\n",
        "for every_test_list in test_list:\n",
        "    label1=every_test_list['label']\n",
        "    label1=torch.tensor([label1])\n",
        "    sprectrome=every_test_list['sprectrome']\n",
        "    with torch.no_grad():\n",
        "      if(sprectrome.shape[2]>65):\n",
        "        #sprectrome = sprectrome.to('cuda')\n",
        "        #label1=label1.to('cuda')\n",
        "        output = model(sprectrome)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        y_actu.append(label1.numpy()[0])\n",
        "        y_pred.append(preds.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNAdE3fQ3z8v"
      },
      "source": [
        "***confusionMatrix***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueItzxt432pq"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_actu, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}