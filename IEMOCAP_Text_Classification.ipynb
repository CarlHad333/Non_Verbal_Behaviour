{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2993857,
          "sourceType": "datasetVersion",
          "datasetId": 1834494
        },
        {
          "sourceId": 7850391,
          "sourceType": "datasetVersion",
          "datasetId": 4603674
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "IEMOCAP - Text Classification",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlHad333/Non_Verbal_Behaviour/blob/main/IEMOCAP_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'iemocapfullrelease:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1834494%2F2993857%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T141520Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D32145445c90bc8cf7d3d5db8e54dc090ea4d05aa0167c444f72e3a572b86652ded02da81a0578ec2400a9cc98c83760b8af36c13f1671c54631d40ce7634c0e9040d059221fda7ed2c0bc71e7c849072f1be7c4390202b63f757a9b48e0e84b80cf4d8f9b60629a8f47182abbb1ce22d1443ae0b50ea5648f5c7ffeb5b20057c6e417682d3642fc83ee45eac50924f4491d703ebd019f18e5be04734d3b304dfb3aecf68f02270e8c9bbf6aa1332d5db651ab9de95f6fc54cef3c112b93763ba462573d10c694665ddeb39ec5ff9be0afa7cf0a17acad7a7420a5d8547c2680080374315f636e4023236c3bad449d444720be62ff413ec240f8514abfce633fb'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "NAoSX9eJkL1k"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas\n",
        "import numpy as np\n",
        "!pip install --upgrade numpy\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:25.683663Z",
          "iopub.execute_input": "2024-03-16T14:31:25.684607Z",
          "iopub.status.idle": "2024-03-16T14:31:38.47174Z",
          "shell.execute_reply.started": "2024-03-16T14:31:25.684564Z",
          "shell.execute_reply": "2024-03-16T14:31:38.470391Z"
        },
        "trusted": true,
        "id": "HrHgdXzMkL1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/kaggle/input/iemocap-csv'\n",
        "\n",
        "df = pandas.read_csv(os.path.join(root_path, 'iemocap.csv'))\n",
        "sessions = [1, 2, 3, 4, 5]\n",
        "df = df[df['session'].isin(sessions)]\n",
        "\n",
        "# Remove unwanted emotions and empty values\n",
        "unwanted_emotions = ['xxx', '', 'oth', 'dis', 'sur', 'fea', 'exc', 'fru']\n",
        "df = df[~df['emotion'].isin(unwanted_emotions)]\n",
        "\n",
        "# Calculate annotator difference\n",
        "df['annotator_difference'] = df['n_annotators'] - df['agreement']\n",
        "\n",
        "# Filter by annotator difference\n",
        "df = df[df['annotator_difference'] <= 1]\n",
        "\n",
        "# Replace 'exc' emotion with 'hap'\n",
        "#df.loc[df['emotion'] == 'exc', 'emotion'] = 'hap'\n",
        "\n",
        "\n",
        "emotions_count_before = df['emotion'].value_counts()\n",
        "print(\"Emotions count before filtering:\")\n",
        "print(emotions_count_before)\n",
        "\n",
        "# Group by emotion and select first 550 rows of each group\n",
        "df = df.groupby('emotion').head(650)\n",
        "\n",
        "# Count the occurrences of each emotion after filtering\n",
        "emotions_count_after = df['emotion'].value_counts()\n",
        "print(\"\\nEmotions count after filtering:\")\n",
        "print(emotions_count_after)\n",
        "\n",
        "# Display the first 5 rows\n",
        "display(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:38.474584Z",
          "iopub.execute_input": "2024-03-16T14:31:38.475027Z",
          "iopub.status.idle": "2024-03-16T14:31:38.657343Z",
          "shell.execute_reply.started": "2024-03-16T14:31:38.474991Z",
          "shell.execute_reply": "2024-03-16T14:31:38.656376Z"
        },
        "trusted": true,
        "id": "ikQvThZ1kL1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: 80% train, 20% remaining\n",
        "df_train, df_remaining = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Second split: 50% valid, 50% test from the remaining 20%\n",
        "df_valid, df_test = train_test_split(df_remaining, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting dataframes\n",
        "print(\"Shape of df_train:\", df_train.shape)\n",
        "print(\"Shape of df_valid:\", df_valid.shape)\n",
        "print(\"Shape of df_test:\", df_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:38.658717Z",
          "iopub.execute_input": "2024-03-16T14:31:38.659075Z",
          "iopub.status.idle": "2024-03-16T14:31:38.672841Z",
          "shell.execute_reply.started": "2024-03-16T14:31:38.659042Z",
          "shell.execute_reply": "2024-03-16T14:31:38.671827Z"
        },
        "trusted": true,
        "id": "v0V5NDFykL1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to split the wav_path into main_path and file_name and convert main_path to the desired format\n",
        "def split_and_convert_path(wav_path):\n",
        "    parts = wav_path.split('/')\n",
        "    main_path_parts = parts[:-3]  # Extract main path parts\n",
        "    session_part = main_path_parts[1]  # Extract the session part (e.g., 'Session1')\n",
        "    script_part = parts[-2]  # Extract the script part (e.g., 'Ses01F_script02_1')\n",
        "    main_path = f'IEMOCAP_full_release/{session_part}/dialog/transcriptions/{script_part}.txt'  # Construct the main path\n",
        "    file_name = parts[-1]  # Extract file name\n",
        "    return main_path, file_name\n",
        "\n",
        "# Apply the split_and_convert_path function to the 'wav_path' column\n",
        "df_train['main_path'], df_train['file_name'] = zip(*df_train['wav_path'].apply(split_and_convert_path))\n",
        "df_valid['main_path'], df_valid['file_name'] = zip(*df_valid['wav_path'].apply(split_and_convert_path))\n",
        "df_test['main_path'], df_test['file_name'] = zip(*df_test['wav_path'].apply(split_and_convert_path))\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(df_train[['main_path', 'file_name', 'emotion']])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:38.675348Z",
          "iopub.execute_input": "2024-03-16T14:31:38.675738Z",
          "iopub.status.idle": "2024-03-16T14:31:38.701591Z",
          "shell.execute_reply.started": "2024-03-16T14:31:38.675711Z",
          "shell.execute_reply": "2024-03-16T14:31:38.700604Z"
        },
        "trusted": true,
        "id": "9HxVMNj2kL1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Assuming your DataFrame is called 'df'\n",
        "def get_transcript(row):\n",
        "    file_path = row['main_path']\n",
        "    wav_file = row['file_name']\n",
        "\n",
        "    file_path = os.path.join('/kaggle/input/iemocapfullrelease',file_path)\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        transcript = ''\n",
        "        for line in f:\n",
        "            match = re.match(r'(.*?)\\s\\[(.*?)\\]:\\s(.*)', line)\n",
        "            if match:\n",
        "                speaker_id = match.group(1)\n",
        "                if speaker_id in wav_file:\n",
        "                    transcript += match.group(3) + ' '\n",
        "\n",
        "    return transcript.strip()\n",
        "\n",
        "df_train['text'] = df_train.apply(get_transcript, axis=1)\n",
        "df_test['text'] = df_test.apply(get_transcript, axis=1)\n",
        "df_valid['text'] = df_valid.apply(get_transcript, axis=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:38.702803Z",
          "iopub.execute_input": "2024-03-16T14:31:38.703683Z",
          "iopub.status.idle": "2024-03-16T14:31:40.907933Z",
          "shell.execute_reply.started": "2024-03-16T14:31:38.703647Z",
          "shell.execute_reply": "2024-03-16T14:31:40.907029Z"
        },
        "trusted": true,
        "id": "ZxCtk_YekL1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train[['main_path', 'file_name', 'emotion', 'text']])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:40.908951Z",
          "iopub.execute_input": "2024-03-16T14:31:40.909221Z",
          "iopub.status.idle": "2024-03-16T14:31:40.922943Z",
          "shell.execute_reply.started": "2024-03-16T14:31:40.909199Z",
          "shell.execute_reply": "2024-03-16T14:31:40.921864Z"
        },
        "trusted": true,
        "id": "6Hr7cW1ZkL10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict, Features, Value, ClassLabel\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['ang', 'hap', 'neu', 'sad']  # Update with your actual class names\n",
        "\n",
        "# Define the features\n",
        "features = Features({\n",
        "    'emotion': ClassLabel(names=class_names),\n",
        "    'text': Value('string')\n",
        "})\n",
        "\n",
        "# Preprocess the 'emotion' column in the dataframes\n",
        "df_train['emotion'] = df_train['emotion'].apply(lambda x: class_names.index(x))\n",
        "df_valid['emotion'] = df_valid['emotion'].apply(lambda x: class_names.index(x))\n",
        "df_test['emotion'] = df_test['emotion'].apply(lambda x: class_names.index(x))\n",
        "\n",
        "# Create individual datasets from the dataframes\n",
        "train_dataset = Dataset.from_pandas(df_train, features=features)\n",
        "valid_dataset = Dataset.from_pandas(df_valid, features=features)\n",
        "test_dataset = Dataset.from_pandas(df_test, features=features)\n",
        "\n",
        "# Create the DatasetDict\n",
        "emotions = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': valid_dataset,\n",
        "    'test': test_dataset\n",
        "})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:40.924682Z",
          "iopub.execute_input": "2024-03-16T14:31:40.924977Z",
          "iopub.status.idle": "2024-03-16T14:31:40.944511Z",
          "shell.execute_reply.started": "2024-03-16T14:31:40.924954Z",
          "shell.execute_reply": "2024-03-16T14:31:40.943503Z"
        },
        "trusted": true,
        "id": "eFiZ1bU_kL11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions['train'][:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:40.9459Z",
          "iopub.execute_input": "2024-03-16T14:31:40.946247Z",
          "iopub.status.idle": "2024-03-16T14:31:40.954312Z",
          "shell.execute_reply.started": "2024-03-16T14:31:40.946216Z",
          "shell.execute_reply": "2024-03-16T14:31:40.953436Z"
        },
        "trusted": true,
        "id": "Qp9EKhwFkL12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Zic5zpcDkL13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:40.955486Z",
          "iopub.execute_input": "2024-03-16T14:31:40.955812Z",
          "iopub.status.idle": "2024-03-16T14:31:40.983909Z",
          "shell.execute_reply.started": "2024-03-16T14:31:40.955789Z",
          "shell.execute_reply": "2024-03-16T14:31:40.982917Z"
        },
        "trusted": true,
        "id": "-vxqElvzkL17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "text = 'Tokenisation of text is a core task of NLP.'\n",
        "\n",
        "# Load parameters of the tokeniser\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Show tokeniser information\n",
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:40.988365Z",
          "iopub.execute_input": "2024-03-16T14:31:40.988724Z",
          "iopub.status.idle": "2024-03-16T14:31:41.141169Z",
          "shell.execute_reply.started": "2024-03-16T14:31:40.988698Z",
          "shell.execute_reply": "2024-03-16T14:31:41.140217Z"
        },
        "trusted": true,
        "id": "EYqj1n6jkL18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Encoded text')\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text,'\\n')\n",
        "\n",
        "print('Tokens')\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens,'\\n')\n",
        "\n",
        "print('Convert tokens to string')\n",
        "print(tokenizer.convert_tokens_to_string(tokens),'\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.14234Z",
          "iopub.execute_input": "2024-03-16T14:31:41.14264Z",
          "iopub.status.idle": "2024-03-16T14:31:41.149073Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.142615Z",
          "shell.execute_reply": "2024-03-16T14:31:41.148091Z"
        },
        "trusted": true,
        "id": "AfCOTfVgkL19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.150145Z",
          "iopub.execute_input": "2024-03-16T14:31:41.150446Z",
          "iopub.status.idle": "2024-03-16T14:31:41.157996Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.150412Z",
          "shell.execute_reply": "2024-03-16T14:31:41.157149Z"
        },
        "trusted": true,
        "id": "pzFoNtqbkL1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions['train'][:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.15904Z",
          "iopub.execute_input": "2024-03-16T14:31:41.159293Z",
          "iopub.status.idle": "2024-03-16T14:31:41.168339Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.15927Z",
          "shell.execute_reply": "2024-03-16T14:31:41.167423Z"
        },
        "trusted": true,
        "id": "YGmyIe_ykL1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisation function\n",
        "def tokenise(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.16964Z",
          "iopub.execute_input": "2024-03-16T14:31:41.16992Z",
          "iopub.status.idle": "2024-03-16T14:31:41.175957Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.169891Z",
          "shell.execute_reply": "2024-03-16T14:31:41.17512Z"
        },
        "trusted": true,
        "id": "EeNAW5_YkL1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenise, batched=True, batch_size=None)\n",
        "print(emotions_encoded[\"train\"].column_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.176841Z",
          "iopub.execute_input": "2024-03-16T14:31:41.17747Z",
          "iopub.status.idle": "2024-03-16T14:31:41.453777Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.17743Z",
          "shell.execute_reply": "2024-03-16T14:31:41.452852Z"
        },
        "trusted": true,
        "id": "qb7hHLgHkL1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#emotions_encoded['train'][:1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.454949Z",
          "iopub.execute_input": "2024-03-16T14:31:41.455246Z",
          "iopub.status.idle": "2024-03-16T14:31:41.459504Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.45522Z",
          "shell.execute_reply": "2024-03-16T14:31:41.458504Z"
        },
        "trusted": true,
        "id": "kmc0jMiikL1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded['train'][:1]['text']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.460724Z",
          "iopub.execute_input": "2024-03-16T14:31:41.461058Z",
          "iopub.status.idle": "2024-03-16T14:31:41.471275Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.461026Z",
          "shell.execute_reply": "2024-03-16T14:31:41.470409Z"
        },
        "trusted": true,
        "id": "1C_pNZdmkL1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = emotions_encoded['train'][:1]['text']\n",
        "print('Encoded text')\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text, '\\n')\n",
        "\n",
        "print('Tokens')\n",
        "tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in encoded_text.input_ids]\n",
        "print(tokens, '\\n')\n",
        "\n",
        "print('Convert tokens to string')\n",
        "print([tokenizer.convert_tokens_to_string(token) for token in tokens], '\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.472442Z",
          "iopub.execute_input": "2024-03-16T14:31:41.473166Z",
          "iopub.status.idle": "2024-03-16T14:31:41.480518Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.473133Z",
          "shell.execute_reply": "2024-03-16T14:31:41.479648Z"
        },
        "trusted": true,
        "id": "TtY8qkGBkL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.481792Z",
          "iopub.execute_input": "2024-03-16T14:31:41.482077Z",
          "iopub.status.idle": "2024-03-16T14:31:41.981037Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.482054Z",
          "shell.execute_reply": "2024-03-16T14:31:41.980236Z"
        },
        "trusted": true,
        "id": "9ziW-VZhkL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "    # Encode text\n",
        "    encoded_text = tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Place model inputs on the GPU\n",
        "    inputs = {k: v.to(device) for k, v in encoded_text.items()}\n",
        "\n",
        "    # Extract last hidden states\n",
        "    with torch.no_grad():\n",
        "        last_hidden_state = model(**inputs).last_hidden_state\n",
        "\n",
        "    # Return vector for [CLS] token\n",
        "    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n",
        "\n",
        "# Extract last hidden states (faster w/ GPU)\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)\n",
        "print(emotions_hidden[\"train\"].column_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:41.9821Z",
          "iopub.execute_input": "2024-03-16T14:31:41.982378Z",
          "iopub.status.idle": "2024-03-16T14:31:45.941437Z",
          "shell.execute_reply.started": "2024-03-16T14:31:41.982356Z",
          "shell.execute_reply": "2024-03-16T14:31:45.940527Z"
        },
        "trusted": true,
        "id": "1D2_pGxakL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden['train']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:45.942716Z",
          "iopub.execute_input": "2024-03-16T14:31:45.942999Z",
          "iopub.status.idle": "2024-03-16T14:31:45.948815Z",
          "shell.execute_reply.started": "2024-03-16T14:31:45.942974Z",
          "shell.execute_reply": "2024-03-16T14:31:45.948004Z"
        },
        "trusted": true,
        "id": "2plCmvZMkL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"emotion\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"emotion\"])\n",
        "print(f'Training Dataset: {X_train.shape}')\n",
        "print(f'Validation Dataset {X_valid.shape}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:45.950062Z",
          "iopub.execute_input": "2024-03-16T14:31:45.95039Z",
          "iopub.status.idle": "2024-03-16T14:31:47.235815Z",
          "shell.execute_reply.started": "2024-03-16T14:31:45.950359Z",
          "shell.execute_reply": "2024-03-16T14:31:47.234781Z"
        },
        "trusted": true,
        "id": "-GQ1RiSakL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Scale the data\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "\n",
        "# lower dimension transformation\n",
        "model = TSNE(n_components=2).fit(X_scaled)\n",
        "\n",
        "# Create a df of 2D embeddings\n",
        "df_embedding = pd.DataFrame(model.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_embedding[\"emotion\"] = y_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:48.608882Z",
          "iopub.execute_input": "2024-03-16T14:31:48.609618Z",
          "iopub.status.idle": "2024-03-16T14:31:57.53498Z",
          "shell.execute_reply.started": "2024-03-16T14:31:48.609586Z",
          "shell.execute_reply": "2024-03-16T14:31:57.534096Z"
        },
        "trusted": true,
        "id": "Mpjm-YzlkL2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='whitegrid')\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
        "axes = axes.flatten()\n",
        "labels = emotions[\"train\"].features[\"emotion\"].names\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "\n",
        "    dict_embedding_sub = dict(tuple(df_embedding.groupby('emotion')))\n",
        "    df_embedding_sub = dict_embedding_sub[i]\n",
        "\n",
        "    axes[i].scatter(df_embedding_sub[\"X\"],\n",
        "                    df_embedding_sub[\"Y\"],\n",
        "                    lw=1,ec='k',alpha=0.2)\n",
        "\n",
        "    axes[i].set_title(f'{label}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:31:58.853323Z",
          "iopub.execute_input": "2024-03-16T14:31:58.854141Z",
          "iopub.status.idle": "2024-03-16T14:32:00.690571Z",
          "shell.execute_reply.started": "2024-03-16T14:31:58.85411Z",
          "shell.execute_reply": "2024-03-16T14:32:00.689589Z"
        },
        "trusted": true,
        "id": "d3D7BBBOkL2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "print(f'accuracy: {dummy_clf.score(X_valid, y_valid)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:32:07.247649Z",
          "iopub.execute_input": "2024-03-16T14:32:07.248333Z",
          "iopub.status.idle": "2024-03-16T14:32:07.255518Z",
          "shell.execute_reply.started": "2024-03-16T14:32:07.2483Z",
          "shell.execute_reply": "2024-03-16T14:32:07.254653Z"
        },
        "trusted": true,
        "id": "gwVEfIWLkL2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "# We increase `max_iter` to guarantee convergence\n",
        "lr_clf = LR(max_iter=2000, random_state=42)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "print(f'accuracy: {lr_clf.score(X_valid, y_valid)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:40:52.327479Z",
          "iopub.execute_input": "2024-03-16T14:40:52.328377Z",
          "iopub.status.idle": "2024-03-16T14:40:56.776319Z",
          "shell.execute_reply.started": "2024-03-16T14:40:52.328341Z",
          "shell.execute_reply": "2024-03-16T14:40:56.775057Z"
        },
        "trusted": true,
        "id": "huaSBt4NkL2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=116, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_predictions = rf_clf.predict(X_valid)\n",
        "rf_accuracy = accuracy_score(y_valid, rf_predictions)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_valid, rf_predictions))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:49:43.249504Z",
          "iopub.execute_input": "2024-03-16T14:49:43.250163Z",
          "iopub.status.idle": "2024-03-16T14:49:47.352713Z",
          "shell.execute_reply.started": "2024-03-16T14:49:43.250132Z",
          "shell.execute_reply": "2024-03-16T14:49:47.351777Z"
        },
        "trusted": true,
        "id": "up3ckONHkL2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Classifier\n",
        "xgb_clf = XGBClassifier(n_estimators=250, random_state=42)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_clf.predict(X_valid)\n",
        "xgb_accuracy = accuracy_score(y_valid, xgb_predictions)\n",
        "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_valid, xgb_predictions))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T14:53:23.486689Z",
          "iopub.execute_input": "2024-03-16T14:53:23.487684Z",
          "iopub.status.idle": "2024-03-16T14:54:12.725324Z",
          "shell.execute_reply.started": "2024-03-16T14:53:23.487646Z",
          "shell.execute_reply": "2024-03-16T14:54:12.724303Z"
        },
        "trusted": true,
        "id": "YdkMv46CkL2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}